# ğŸ”´ Redis: Your Shared Nervous System

This document explains how Redis will serve as the **central hub** for caching, sessions, rate limiting, job storage, and more across your entire TechBirdsFly ecosystem.

---

## ğŸ“Š Redis Role Overview

```
Redis 7.4-Alpine (Single Instance - 6379)
â”‚
â”œâ”€ 1ï¸âƒ£ CACHING (Already Implemented) âœ…
â”‚  â”œâ”€ Auth: Token cache (1h TTL) â†’ 3 endpoints
â”‚  â”œâ”€ Billing: Summary cache (30m TTL) â†’ 3 endpoints
â”‚  â”œâ”€ Admin: Template cache (1h TTL) â†’ 11 endpoints
â”‚  â”œâ”€ Image: Metadata cache (1h TTL) â†’ 4 endpoints
â”‚  â”œâ”€ User: Profile cache (30m TTL) â†’ 3 endpoints
â”‚  â””â”€ Generator: Project cache (10m TTL) â†’ 3 endpoints
â”‚  â””â”€ Impact: 37 endpoints, 92.8% DB query reduction
â”‚
â”œâ”€ 2ï¸âƒ£ RATE LIMITING (Gateway Use Case)
â”‚  â”œâ”€ Per-user counters (100 req/min)
â”‚  â”œâ”€ Per-IP counters (10 req/min anonymous)
â”‚  â”œâ”€ DDoS protection (50 req/30s per IP)
â”‚  â””â”€ Fast lookup (< 1ms)
â”‚
â”œâ”€ 3ï¸âƒ£ SESSION STORE (Future)
â”‚  â”œâ”€ ASP.NET Core session data
â”‚  â”œâ”€ User preferences
â”‚  â””â”€ Temporary request data
â”‚
â”œâ”€ 4ï¸âƒ£ MESSAGE QUEUE FALLBACK (Planned)
â”‚  â”œâ”€ Redis Streams for async messaging
â”‚  â”œâ”€ Lightweight alternative to RabbitMQ for POC
â”‚  â””â”€ Consumer groups for guaranteed delivery
â”‚
â”œâ”€ 5ï¸âƒ£ HANGFIRE JOB STORE (Phase 3)
â”‚  â”œâ”€ Background job scheduling
â”‚  â”œâ”€ Recurring job state
â”‚  â”œâ”€ Job history
â”‚  â””â”€ Retry coordination
â”‚
â”œâ”€ 6ï¸âƒ£ FEATURE TOGGLES (Phase 4)
â”‚  â”œâ”€ Global feature flags
â”‚  â”œâ”€ Per-user feature access
â”‚  â”œâ”€ Zero-deployment rollouts
â”‚  â””â”€ TTL-based automatic expiration
â”‚
â””â”€ 7ï¸âƒ£ DISTRIBUTED LOCKS (Planned)
   â”œâ”€ Prevent duplicate invoice generation
   â”œâ”€ Coordinate background jobs
   â””â”€ Mutex across service instances
```

---

## ğŸ¯ Current Implementation (Phase 0 - Complete)

### Cache-Aside Pattern

All 6 services currently use the same pattern:

```csharp
// 1. Check cache
var cacheKey = $"endpoint:{id}";
var cached = await _cache.GetAsync<YourType>(cacheKey);
if (cached != null)
    return Ok(cached); // Cache hit!

// 2. If not cached, fetch from database
var data = await _database.GetAsync(id);
if (data == null)
    return NotFound();

// 3. Store in cache with TTL
var ttl = TimeSpan.FromMinutes(10); // or 30min, 1h, etc.
await _cache.SetAsync(cacheKey, data, ttl);

return Ok(data);
```

**Current Stats**:
- Services: 6/6 implemented âœ…
- Endpoints cached: 37
- Expected cache hit rate: 75-92%
- Database query reduction: 92.8%
- Performance improvement: 55x faster average
- Memory usage: ~50MB Redis (with 10-minute data)

---

## ğŸš€ Phase 2: Rate Limiting with Redis

Your **YARP Gateway** already rate limits, but it's using in-memory counters. Move to Redis for **distributed rate limiting** (useful when scaling to multiple gateway instances).

### Implementation

```csharp
// RateLimitService.cs
public class RateLimitService
{
    private readonly IDistributedCache _cache;
    
    public async Task<(bool IsAllowed, int Remaining, int ResetSeconds)> CheckLimitAsync(
        string userId, 
        int maxRequests, 
        int windowSeconds)
    {
        var key = $"rate-limit:{userId}";
        
        // Get current count
        var countStr = await _cache.GetStringAsync(key);
        var count = int.TryParse(countStr, out var c) ? c : 0;
        
        if (count >= maxRequests)
        {
            // Rate limit exceeded
            var ttl = await _cache.GetAsync(key + ":ttl");
            var resetSeconds = ttl?.Length ?? windowSeconds;
            return (false, 0, resetSeconds);
        }
        
        // Increment counter
        count++;
        await _cache.SetStringAsync(
            key, 
            count.ToString(), 
            new DistributedCacheEntryOptions
            {
                AbsoluteExpirationRelativeToNow = TimeSpan.FromSeconds(windowSeconds)
            });
        
        return (true, maxRequests - count, windowSeconds);
    }
}
```

### Usage in Gateway Middleware

```csharp
public class RateLimitMiddleware
{
    private readonly RequestDelegate _next;
    private readonly RateLimitService _rateLimitService;

    public async Task InvokeAsync(HttpContext context)
    {
        var userId = context.User?.FindFirst(ClaimTypes.NameIdentifier)?.Value 
            ?? context.Connection.RemoteIpAddress?.ToString() 
            ?? "anonymous";
        
        var (isAllowed, remaining, resetSeconds) = 
            await _rateLimitService.CheckLimitAsync(userId, maxRequests: 100, windowSeconds: 60);
        
        context.Response.Headers.Add("X-RateLimit-Limit", "100");
        context.Response.Headers.Add("X-RateLimit-Remaining", remaining.ToString());
        context.Response.Headers.Add("X-RateLimit-Reset", resetSeconds.ToString());
        
        if (!isAllowed)
        {
            context.Response.StatusCode = StatusCodes.Status429TooManyRequests;
            await context.Response.WriteAsync("Rate limit exceeded");
            return;
        }
        
        await _next(context);
    }
}
```

**Why Redis?**
- Multiple gateway instances share the same counters
- Atomic increment operations
- Automatic TTL cleanup
- Sub-millisecond lookups

---

## ğŸ“¨ Phase 2b: Redis Streams (Message Queue Alternative)

For MVP, instead of adding RabbitMQ complexity, use **Redis Streams**:

```csharp
// EventPublisher using Redis Streams
public class RedisStreamEventPublisher : IEventBus
{
    private readonly IConnectionMultiplexer _redis;
    
    public async Task PublishAsync<T>(T message, string? routingKey = null) where T : IEvent
    {
        var db = _redis.GetDatabase();
        
        var json = JsonSerializer.Serialize(message);
        var streamKey = $"stream:{message.EventType}";
        
        // Publish to stream (survives service restarts)
        await db.StreamAddAsync(
            streamKey,
            new NameValueEntry[]
            {
                new NameValueEntry("data", json),
                new NameValueEntry("timestamp", DateTime.UtcNow.Ticks.ToString())
            });
    }
    
    public async Task SubscribeAsync<T>(Func<T, Task> handler) where T : IEvent
    {
        var db = _redis.GetDatabase();
        var streamKey = $"stream:{typeof(T).Name}";
        
        var groupName = "default-group";
        
        // Create consumer group if not exists
        try
        {
            await db.StreamGroupCreateAsync(streamKey, groupName, "$", createStream: true);
        }
        catch
        {
            // Group already exists
        }
        
        // Read messages
        while (true)
        {
            var messages = await db.StreamReadGroupAsync(
                streamKey,
                groupName,
                Environment.MachineName, // consumer name
                count: 10);
            
            foreach (var message in messages)
            {
                var json = message.Values.FirstOrDefault(v => v.Name == "data").Value.ToString();
                var obj = JsonSerializer.Deserialize<T>(json)!;
                
                await handler(obj);
                
                // Mark as processed
                await db.StreamAcknowledgeAsync(streamKey, groupName, message.Id);
            }
            
            await Task.Delay(1000); // Poll every second
        }
    }
}
```

**Advantages**:
- No additional infrastructure (Streams are built-in to Redis)
- Persistent messages (survives restarts)
- Consumer groups (load balancing)
- Simple pub/sub without Kafka complexity

---

## ğŸ’¾ Phase 3: Hangfire Job Store Configuration

Configure Hangfire to use Redis as its backing store:

### Installation

```bash
dotnet add package Hangfire.Core
dotnet add package Hangfire.AspNetCore
dotnet add package Hangfire.Redis.StackExchange
```

### Program.cs Setup

```csharp
builder.Services.AddHangfire(config => config
    .SetDataCompatibilityLevel(CompatibilityLevel.Version_180)
    .UseSimpleAssemblyNameTypeSerializer()
    .UseRecommendedSerializerSettings()
    .UseRedisStorage(
        builder.Configuration.GetConnectionString("Redis"),
        new RedisStorageOptions
        {
            Prefix = "hangfire:",
            Db = 1, // Use separate DB from cache (DB 0)
            InvisibilityTimeout = TimeSpan.FromMinutes(30),
            ExpirationTime = TimeSpan.FromDays(7)
        }));

builder.Services.AddHangfireServer(options =>
{
    options.SchedulePollingInterval = TimeSpan.FromSeconds(15);
    options.ServerName = $"{Environment.MachineName}:BillingService";
});
```

### Why Separate Redis DBs?

```
Redis Instance (Port 6379)
â”‚
â”œâ”€ DB 0: Cache (default)
â”‚  â”œâ”€ auth:token:*
â”‚  â”œâ”€ billing:summary:*
â”‚  â””â”€ project:*
â”‚
â””â”€ DB 1: Hangfire Jobs
   â”œâ”€ hangfire:job:*
   â”œâ”€ hangfire:schedule:*
   â””â”€ hangfire:queue:*
```

**Configuration**:

```json
{
  "ConnectionStrings": {
    "Redis": "techbirdsfly-redis:6379,defaultDatabase=0,abortConnect=false"
  }
}
```

### Example Recurring Job

```csharp
public class InvoiceService
{
    private readonly IBillingRepository _repo;
    private readonly IEmailService _email;
    private readonly ILogger<InvoiceService> _logger;

    [AutomaticRetry(Attempts = 3)]
    public async Task GenerateMonthlyInvoicesAsync()
    {
        _logger.LogInformation("Starting monthly invoice generation");
        
        try
        {
            var users = await _repo.GetActiveSubscribersAsync();
            
            foreach (var user in users)
            {
                var invoice = await _repo.GenerateInvoiceAsync(user.Id);
                await _email.SendInvoiceAsync(user.Email, invoice);
            }
            
            _logger.LogInformation("Monthly invoices generated: {Count}", users.Count);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to generate invoices");
            throw;
        }
    }
}

// In Program.cs or startup
RecurringJob.AddOrUpdate<InvoiceService>(
    "generate-monthly-invoices",
    x => x.GenerateMonthlyInvoicesAsync(),
    Cron.Monthly(1, 0)); // 1st of month at midnight
```

---

## ğŸš© Phase 4: Feature Toggles

Use Redis for feature flags that can be toggled without redeployment:

```csharp
public interface IFeatureToggleService
{
    Task<bool> IsEnabledAsync(string featureName, string? userId = null);
    Task SetAsync(string featureName, bool enabled, TimeSpan? expiration = null);
}

public class RedisFeatureToggleService : IFeatureToggleService
{
    private readonly IDistributedCache _cache;

    public async Task<bool> IsEnabledAsync(string featureName, string? userId = null)
    {
        var key = userId != null 
            ? $"feature:{featureName}:user:{userId}" 
            : $"feature:{featureName}:global";
        
        var value = await _cache.GetStringAsync(key);
        return value == "true";
    }

    public async Task SetAsync(string featureName, bool enabled, TimeSpan? expiration = null)
    {
        var key = $"feature:{featureName}:global";
        
        var options = new DistributedCacheEntryOptions();
        if (expiration.HasValue)
            options.AbsoluteExpirationRelativeToNow = expiration;
        
        await _cache.SetStringAsync(key, enabled.ToString(), options);
    }
}
```

### Usage in Controllers

```csharp
public class GeneratorController
{
    private readonly IFeatureToggleService _features;

    [HttpPost("projects")]
    public async Task<IActionResult> CreateProject(CreateProjectRequest req)
    {
        // Check if feature is enabled
        if (!await _features.IsEnabledAsync("advanced-ai-models"))
        {
            // Fallback to simpler model
            req.Model = "gpt-4";
        }
        
        // Continue normally
        return Ok(new { projectId = "...", status = "generating" });
    }
}
```

### Command-Line Toggle

```bash
# Enable feature globally (7-day expiration)
redis-cli SET feature:advanced-ai-models:global true EX 604800

# Disable feature
redis-cli SET feature:advanced-ai-models:global false

# Check current value
redis-cli GET feature:advanced-ai-models:global
```

---

## ğŸ”’ Distributed Locks (Advanced)

Prevent duplicate execution across multiple service instances:

```csharp
public class DistributedLockService
{
    private readonly IConnectionMultiplexer _redis;

    public async Task<bool> AcquireLockAsync(string lockKey, string lockValue, TimeSpan? expiration = null)
    {
        var db = _redis.GetDatabase();
        
        return await db.StringSetAsync(
            lockKey,
            lockValue,
            expiration ?? TimeSpan.FromMinutes(10),
            When.NotExists); // Only set if doesn't exist
    }

    public async Task<bool> ReleaseLockAsync(string lockKey, string lockValue)
    {
        var db = _redis.GetDatabase();
        
        // Compare and delete (atomic)
        var script = @"
            if redis.call('get', KEYS[1]) == ARGV[1] then
                return redis.call('del', KEYS[1])
            else
                return 0
            end";
        
        var result = await db.ScriptEvaluateAsync(script, new RedisKey[] { lockKey }, new RedisValue[] { lockValue });
        return (long)result == 1;
    }
}

// Usage: Prevent duplicate invoice generation
public async Task GenerateMonthlyInvoicesAsync()
{
    var lockKey = "job:generate-invoices:monthly";
    var lockValue = Guid.NewGuid().ToString();
    
    // Try to acquire lock
    if (!await _lockService.AcquireLockAsync(lockKey, lockValue, TimeSpan.FromMinutes(30)))
    {
        _logger.LogInformation("Invoice generation already in progress, skipping");
        return;
    }
    
    try
    {
        // Do work...
        await GenerateInvoicesAsync();
    }
    finally
    {
        await _lockService.ReleaseLockAsync(lockKey, lockValue);
    }
}
```

---

## ğŸ“Š Redis Monitoring & Optimization

### View Redis Memory Usage

```bash
# Connect to Redis
redis-cli

# Check memory statistics
INFO memory

# View all keys with size
MEMORY DOCTOR

# Get cache hit rate
INFO stats
# Look for: keyspace_hits, keyspace_misses
```

### Optimization Tips

```bash
# 1. Set memory limit
CONFIG SET maxmemory 256mb

# 2. Set eviction policy (remove oldest when full)
CONFIG SET maxmemory-policy allkeys-lru

# 3. Monitor slow commands
SLOWLOG GET 10

# 4. Check DB size
DBSIZE

# 5. Flush cache if needed
FLUSHDB  # Current DB only
FLUSHALL # All DBs (WARNING: affects caching AND Hangfire!)
```

### Performance Metrics

```bash
# Throughput
INFO stats | grep instant_ops_per_sec

# Latency
LATENCY LATEST

# Persistence
INFO persistence

# Replication
INFO replication
```

---

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Your Services (6)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        RedisCacheService (ICacheService)          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ GetAsync<T>() â†’ Get from cache             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ SetAsync<T>() â†’ Store in cache with TTL    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ RemoveAsync() â†’ Delete from cache          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ ExistsAsync() â†’ Check if key exists        â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  StackExchange.Redis Client (v2.7.0)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      â”‚ (TCP Port 6379)
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Redis 7.4-Alpine              â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                 â”‚
        â”‚  DB 0: Cache (Default)          â”‚
        â”‚  â”œâ”€ Cache Keys (20,000+)        â”‚
        â”‚  â”œâ”€ Session Data (TTL)          â”‚
        â”‚  â””â”€ Rate Limit Counters         â”‚
        â”‚                                 â”‚
        â”‚  DB 1: Hangfire                 â”‚
        â”‚  â”œâ”€ Job Queue                   â”‚
        â”‚  â”œâ”€ Recurring Jobs              â”‚
        â”‚  â”œâ”€ Job History                 â”‚
        â”‚  â””â”€ Failed Jobs (DLQ)           â”‚
        â”‚                                 â”‚
        â”‚  Memory: ~256MB max             â”‚
        â”‚  Persistence: AOF + RDB         â”‚
        â”‚  Replication: None (single)     â”‚
        â”‚                                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Redis Roadmap

### Currently Done âœ…
1. Cache-Aside Pattern (37 endpoints)
2. Docker image configured
3. Health checks integrated
4. All services connected

### Phase 1 (Next) â³
1. Rate limiting (Gateway)
2. Correlation ID storage (Tracing)
3. Session store (ASP.NET Core)

### Phase 2 (Following) 
1. Redis Streams (Message Queue)
2. Hangfire Job Store
3. Feature Toggles

### Phase 3 (Later)
1. Distributed Locks
2. Metrics aggregation
3. Cache warming strategies

---

## ğŸš€ Getting Started with Redis CLI

```bash
# Connect to Redis
docker exec -it techbirdsfly-redis redis-cli

# Basic commands
PING              # Test connection
INFO              # Server statistics
DBSIZE            # Total keys in DB
KEYS *            # List all keys (WARNING: slow on large DB)
KEYS cache:*      # List all cache keys

# Monitor in real-time
MONITOR           # See all commands being executed

# Check specific key
GET cache:user:123
TTL cache:user:123

# Set value with expiration
SET test-key "hello" EX 3600

# Use Redis in Python
pip install redis
python -c "import redis; r = redis.Redis(host='localhost', port=6379); print(r.ping())"
```

---

## ğŸ“– References

- **StackExchange.Redis**: https://stackexchange.github.io/StackExchange.Redis/
- **Redis Official**: https://redis.io/
- **Hangfire + Redis**: https://docs.hangfire.io/en/latest/
- **Redis Streams**: https://redis.io/topics/streams-intro

---

**Redis is now your microservices' "nervous system" â€” fast, distributed, and persistent.** ğŸ”´âš¡

**Next: Implement Phase 1 observability (Serilog + Jaeger) using templates from `PHASE1_CODE_TEMPLATES.md`**
